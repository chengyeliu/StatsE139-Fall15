\documentclass[10pt,landscape]{article}
\usepackage{multicol}
\usepackage{calc}
\usepackage{ifthen}
\usepackage[landscape]{geometry}
\usepackage{amsmath,amsthm,amsfonts,amssymb}
\usepackage{color,graphicx,overpic}
\usepackage{hyperref}


\pdfinfo{
  /Title (example.pdf)
  /Creator (TeX)
  /Producer (pdfTeX 1.40.0)
  /Author (David Wihl)
  /Subject (Cheat Sheet)
  /Keywords (pdflatex, latex,pdftex,tex)}

% This sets page margins to .5 inch if using letter paper, and to 1cm
% if using A4 paper. (This probably isn't strictly necessary.)
% If using another size paper, use default 1cm margins.
\ifthenelse{\lengthtest { \paperwidth = 11in}}
    { \geometry{top=.5in,left=.5in,right=.5in,bottom=.5in} }
    {\ifthenelse{ \lengthtest{ \paperwidth = 297mm}}
        {\geometry{top=1cm,left=1cm,right=1cm,bottom=1cm} }
        {\geometry{top=1cm,left=1cm,right=1cm,bottom=1cm} }
    }

% Turn off header and footer
\pagestyle{empty}

% Redefine section commands to use less space
\makeatletter
\renewcommand{\section}{\@startsection{section}{1}{0mm}%
                                {-1ex plus -.5ex minus -.2ex}%
                                {0.5ex plus .2ex}%x
                                {\normalfont\large\bfseries}}
\renewcommand{\subsection}{\@startsection{subsection}{2}{0mm}%
                                {-1explus -.5ex minus -.2ex}%
                                {0.5ex plus .2ex}%
                                {\normalfont\normalsize\bfseries}}
\renewcommand{\subsubsection}{\@startsection{subsubsection}{3}{0mm}%
                                {-1ex plus -.5ex minus -.2ex}%
                                {1ex plus .2ex}%
                                {\normalfont\small\bfseries}}
\makeatother

\newcommand{\overbar}[1]{\mkern 1.5mu\overline{\mkern-1.5mu#1\mkern-1.5mu}\mkern 1.5mu}


% Define BibTeX command
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

% Don't print section numbers
\setcounter{secnumdepth}{0}


\setlength{\parindent}{0pt}
\setlength{\parskip}{0pt plus 0.5ex}

%My Environments
\newtheorem{example}[section]{Example}
% -----------------------------------------------------------------------

\begin{document}
\raggedright
\footnotesize
\begin{multicols*}{3}


% multicol parameters
% These lengths are set only within the two main columns
%\setlength{\columnseprule}{0.25pt}
\setlength{\premulticols}{1pt}
\setlength{\postmulticols}{1pt}
\setlength{\multicolsep}{1pt}
\setlength{\columnsep}{2pt}
\setlength{\columnseprule}{1pt}


\subsubsection{Basics}

\begin{tabular}{| c | c | c| }
\hline
 & Sample statistic &  Population Parameter \\
 \hline
 Mean & $\overbar{X}$ & $\mu$ \\
 Variance & $S^2$ & $\sigma^2$ \\
 Correlation & $r$ & $\rho$ \\
  Noise & $e_i$ & $\epsilon_i$ \\
\hline
& Guess & True, but unknown \\
\hline
\end{tabular}

The Mean, Variance and StdDev are subject to outliers.
\begin{align*}
\overbar{X} =& \frac{1}{n} \sum\limits_{i=1}^n x_i \\
\mu = E(W) =& E(a + bX) = a + bE(X)\\
\sigma^2 = Var(X) =& E[X^2] - \mu_x^2\\
S^2 =& \sum\limits_{all\ i} \frac{(X_i - \overbar{X})^2}{n-1}\\
\sigma = StdDev(X) =& \sqrt{\sigma^2}\\
Var(X) =& E[(X - \mu)^2]  = E(X^2) - \mu^2\\
	=& \sum_{all x} (x - \mu_x)^2 P(X = x)\\
	=& E(X^2) - E(X)^2 = E(X - E(X))^2\\
Var(X + c) =& Var(X)\\
Var(cX) =& c^2Var(X)\\
Var(\bar{X}) =& \frac{\sigma^2}{n} \\
 \text{If X,Y are dependent}\\
Var(X+Y) \ne& Var(X) + Var(Y)\\
Var(X + Y) =& Var(X - Y)\\
Var((a + bX) + (c + dY)) =& b^2Var(X) + d^2Var(Y) + 2bdCov(X,Y)\\
Var(aX + bY) =& a^2 Var(X) + b^2(Y) + 2abCov(X,Y) \\
	=& a^2 Var(X) + b^2(Y) + 2ab\sigma_x \sigma_y \rho_{xy}\\
\end{align*}
Quartiles split the data into 4 equal groups by number of values, or 25\% percentiles.
Q2 is the median.

\subsubsection{Study Design}

Types of variables: categorical vs. quantitative, dummy, discrete vs continuous.
Observational vs Experiments. Only experimentals can show causal effects.
Key factors to an experiment: control group, randomized, and replicated. Usually 30 replications is sufficient.
Avoid confounding by having cross-over groups.

\textbf{Scope of Inference}: \textbf{Interval Validity}: low when 1) unaccounted confounding factors, 2) ignored missing data 3) noncompliance 4) unverified assumptions
5) suboptimal method of analysis. Applicable when allocation of units to groups is random.
 \textbf{External Validity}: high when can be generalized to population. Applicable when selection of units is random.


\subsubsection{Covariance and Correlation}
Covariance gives direction.\\
Correlation gives direction and strength.\\
Both are \textit{linear}.
\begin{align*}
Cov(X, Y) =& \frac{1}{N} \sum\limits_{i=1}^{N} {(x_i - \overbar{x})(y_i - \overbar{y})} \\
Cor =& \frac{Cov}{\sigma_x \cdot \sigma_y}\\
\end{align*}



\subsubsection{Probabilities}
$ 0 \leq $ All probabilities $ \leq 1 $\\
\textit{Mutually exclusive and Exhaustive}\\
\begin{align*}
P(\overbar{A}) =& 1 - P(A)\\
P(A \text{ or } B) =& P(A) + P(B) - P(A \text{ and } B)\\
P(A \vert B) =& \frac{P(A \text{ and } B)}{P(B)}\\
P(B) =& \sum_{i=1}^n P(B \cap A_i) = \sum_{i=1}^n P(B | A_i)((A_i)\\
{n \choose k} =& \frac{n!}{k!(n-k)!} \\
\end{align*}
Joint vs. Marginal probabilities\\
Independent if $P(A\vert B) = P(A)$\\
For Independent only: $P(E \text{ and } F) = P(E)\cdot P(F)$\\
\begin{tabular}{| c | c | c |}

\hline
&B &$\overbar{B}$\\
\hline
A & $P(A and B) = P(B)P(A \vert B)$ & $P(A and \overbar{B}) = P(\overbar{B})P(A \vert \overbar{B})$\\
$\overbar{A}$ & $P(\overbar{A} and B) = P(\overbar{A})P(B\vert \overbar{A})$ & $ P(\overbar{A}  and \overbar{B}) = P(\overbar{A})P(\overbar{B} \vert \overbar{A})$ \\
\hline
\end{tabular}

\begin{tabular}{| c | c |}
\hline
all success & $p^n$\\
all failure & $(1-p)^n$\\
at least one failure & $1-p^n$\\
at least one success & $1 - (1-p)^n$\\
\hline
\end{tabular}


\subsubsection{Random Variables}
\begin{align*}
P(X \le x) \rightarrow& CDF\\
E(cX) =& c\cdot E(X)\\
E(X+c) =& E(X) + c\\
E(X+Y) =& E(X) + E(Y)\\
\end{align*}

If $X_1, \ldots , X_n \sim N(\mu, \sigma^2)$ then $\bar{X} \sim N(\mu_{\bar{X}} = \mu, \sigma^2_{\bar{X}} = \sigma^2/n)$. If pop dist is not normal, $S^2$ will eventually be Normal
but may not be independent.


\subsubsection{Bias of an Estimator}
In practice $n$ has to relatively much larger like $> 100$.



Guesses should be \textit{unbiased} and have \textit{minimum variance}. MVUE (Minimum Variance, Unbiased Estimates).
\[
bias(\hat{\theta}) = E(\hat{\theta}) - \theta
\]
Unbiased if $bias = 0$ (expected value equals true, not a particular value of $\overbar{x}$). 

For samples, we divide by $n-1$ instead of $n$ to make an unbiased estimator. The guess would otherwise be too low.
\[
E(X) = \sum_{all x} xP(X=x) 
\]
\[
E(\overbar{X}) = \sum\limits_{i=1}^{\infty} x_i p_i =  \mu
\]
\[
E(S^2) = \sigma^2
\]
\begin{align*}
E[X + c] =& E[X] + c\\
E[X + Y] =& E[X] + E[Y]\\
E[aX] =& a E[X]\\
E[aX + bY + c] =& aE[X] + bE[Y] +c\\
E((a + bX) + (c_dY)) =& a + bE(X) + c + dE(Y)\\
\end{align*}
Example: Roulette has a \$1 bet with a \$35 payoff for $\frac{1}{38}$ odds.
\[
E[\text{gain from a \$1 bet}] = -\$1 \cdot \frac{37}{38} + \$35 \cdot \frac{1}{38} = -\$0.0526
\]


\subsubsection{Uniform Distribution}
\begin{align*}
E(X) =& \frac{(a+b)}{2}\\
Var(X) =& \frac{(b-a)^2}{12} \\
\end{align*}
\ \ $y$ axis should be a fraction to make area $=1$

\subsubsection{Normal Distribution}
\begin{align*}
X \sim& \mathcal{N}(\mu,\sigma^2)\\
Z = &\frac{X - \mu}{\sigma} \sim \mathcal{N}(0,1)\\
X = &\sigma Z + \mu \\
\Phi(z) =& \text{distribution} \\
P(a \leq X \leq b) =& P[(a-\mu) \leq (X-\mu) \leq (b-\mu)]\\
	= & P[\frac{(a-\mu)}{\sigma} \leq \frac{(X-\mu)} {\sigma} \leq \frac {(b-\mu)} {\sigma} ]\\
	= & P[\frac{(a-\mu)}{\sigma} \leq Z \leq \frac {(b-\mu)} {\sigma} ]\\
\end{align*}
Linear combination of normals is normal. Used by CLT.


\subsubsection{Binomial Distribution}

\begin{itemize}
\item{$n$ independent trials}
\item{binary result}
\item{same probability of success}
\item{total number of successes}
\end{itemize}
\begin{align*}
X \sim& Bin(n,p)\\
\binom{n}{x} =& \frac{n!}{x!(n-x)!}\\
P(X=x) =& \frac{n!}{x!(n-x)!}p^xq^{(n-x)}\\
\mu_x = E(X) =& n \cdot p\\
\sigma^2 = Var(X) =& n \cdot p \cdot q = n \cdot p \cdot (1-p)\\
X \sim& N(\mu =np, \sigma = \sqrt{np(1-p)}) \\
\hat{p} \sim& N(\mu = p, \sigma\sqrt{p(1-p)/n} ) \\
\end{align*}
Shape of distribution depends on $p,n$.\\
Small $p$, left skewed. Large $p$, right skewed




\subsection{Hypothesis Test - General}
A \textbf{scientific hypothesis} makes a testable statement about the observable universe.

A \textbf{statistical hypothesis} is more restricted. It concerns the behavior of a measurable (or observable) 
random variable. It is often a statement or claim about a parameter of a population or distribution.

\begin{enumerate}
\item Formulate hypotheses ($H_0, H_a, \alpha$)
\item Calculate test statistic and reference distrib.
\item Calculate $p$-value based on reference distribution of test statistic $|H_0$. \textbf{$p$ value is NOT the probability that the null hypothesis is true.} 
It is probablity of seeing our data on the null hypothesis. 
\item Determine conclusion and scope of inference
\end{enumerate}
\textbf{Note:} $t$ values are measures of \textit{distance}. $p$ values are measure of \textit{probability}. Assumptions? Independence? Distribution of Observations? Parametric vs. non-parametric?

\begin{tabular}{ c  c }
Hypotheses & Decision Rule \\
\hline
$H_0 : \mu = \mu_0$ \\      $H_a : \mu \neq \mu_0$ & If $|t_{stat}| > 1.96$, reject $H_0$ \\
 & \\
$H_0 : \mu = \mu_0$ \\ $H_a : \mu < \mu_0$      & If $t_{stat} < -1.64$, reject $H_0$ \\
 & \\
$H_0 : \mu = \mu_0$ \\ $H_a : \mu > \mu_0$      & If $t_{stat} > 1.64$, reject $H_0$ \\
\end{tabular}


Assumptions:
\begin{enumerate}
\item Observations are \textbf{independent}. This is true if the sample is randomly selected, but false if there is bias in the sampling.
\item \textbf{Normal Distributions} of the observations. This happens when the sample is large enough (via the Central Limit Theorm) or it is known that the population is normally distributed.
\end{enumerate}

If these assumptions are not correct, none of the $t$-tests will work correctly.


\subsubsection{Hypothesis Test - Mean}

Calculation by hand using a $t$ test:
\begin{align*}
t_{stat} =& \frac{ \overbar{x} - \mu_0  } { s / \sqrt{n}  } \\
\end{align*}



\subsection{Fisher's Randomization Test}

For casual inference in experiments. No assumption as to the underlying distribution has to be made. Generally, is $\mu_1 = \mu_2$? 

The only assumption is Additive Treatment Effect ($\delta$):
\[
Y_{c,i} = Y_{v,i} + \delta
\]

$H_0: \delta = 0$, ie  zero treatment effect for all units. $H_a: \delta \neq 0$ non-zero treatment effect for ALL units. Reference distrib built through simulation. Non-parametric.

Assumptions:
\begin{itemize}
\item Random assignment to groups
\item Under $H_0$, \textit{independence, interchangability} of study units. 
\end{itemize}

Test Statistic: Difference of outcomes of the two groups: (could also use difference between the medians)
\[
\hat{\delta} = \overbar{Y}_c - \overbar{Y}_v
\]

The maximum number of possible simulations is the binomial distribution:
\[{t \choose s}\]
where $t$ is the total number of study units and $s$ is the number where the effect was shown.

Calculating $p$ value: The $p$ value is proportion of values above or below the observed test statistic.
\begin{align*}
\hat{\delta} =& 0.5\\
p =& P(\overbar{Y}_c - \overbar{Y}_v \geq \overbar{y}_c - \overbar{y}_v) \\
   =& P(\overbar{Y}_c - \overbar{Y}_v \geq 0.5) = 0.029
\end{align*}

so there is sufficient evidence to reject the null.

Scope of inference: Internal Validity maybe not if the same hospital. External validity: possibly not, as these were volunteers.

\subsubsection{Permutation Test}
For observational studies, comparing two groups - for generalization. Means of observations are presumed the same $E(Y_{1,i}) = \mu_1, E(Y_{2,j}) = \mu_2. H_0  : \mu_1 = \mu_2$.

Test stat: $\hat{D} = \bar{Y}_i - \bar{Y}_1$. Reference distrib by simulation. 
Assumes independence of study units and groups, nonparametric, similar shapes and spreads.

\subsubsection{All Things $\chi^2$}

\begin{align*}
\chi^2_1 =& Z^2 \\
\chi^2_n =& \sum\limits_{i=1}^n Z^2_i \\
t_n =& \frac{Z} {\sqrt{\chi^2_n / n} } \\
F_{n,m} =& \frac{ \chi^2_n / n} { \chi^2_m / m } \\
\chi^2_{n+m} =& \chi^2_n + \chi^2_m \\
\frac{(n-1) S^2} {\sigma^2} \sim& X^2_{df = n-1} \\
S^2 = \frac{1}{n-1}\sum\limits_{i=1}^n (X_i - \overbar{x})^2 \sim& \frac{\sigma^2}{n-1}\chi^2_{df=n-1} \\
\end{align*}

\subsection{The $t$ distribution}
The $t$ distribution has a slightly wider spread in the tails than Standard Normal. Also known as student-t distribution. This happens when you don't know the
real $\sigma$ and are forced to use $S$, which is less reliable.

\[
\overbar{X} \approx N(\mu, \frac{\sigma^2}{n})
\]

allows us to Z-score
\[
Z = \frac{\overbar{X} - \mu}{\sigma / \sqrt{n}}
\]
but we don't know $\sigma$ so in practice we use
\[
T = \frac{\overbar{X} - \mu}{S / \sqrt{n}} \sim t_{n-1}
\]
(which has two random variables ($\overbar{X}$ and $S$). Now, take that previous definition of $T$ and add $\sigma/\sqrt{n}$ to the top and bottom:

\begin{align*}
T =& \frac{\overbar{X} - \mu}{S / \sqrt{n}} \\
   =&  \frac{(\overbar{X} - \mu) / (\sigma/\sqrt{n})}{(S / \sqrt{n}) / (\sigma/\sqrt{n})}\\
   =& \frac{Z}{\sqrt{S^2/\sigma^2}}\\
   =& \frac{Z}{\sqrt{\frac{(n-1)S^2}{(n-1)\sigma^2}}} \\
 =&  \frac{Z}{\sqrt{\chi^2/df}}\text{, since }\chi^2 = \frac{(n-1)S^2}{\sigma^2}
\end{align*}

Assumptions: 1) Observations are independent (randomly selected), 2) Normal distrib of observations (either $>30$ via CLT or pop. is known $ \sim N(\mu,\sigma^2)$).



\subsubsection{Confidence Intervals}

CI is Estimate $\pm$ margin of error or Estimate $\pm$ ($z$ value) $\times$ (SD of estimate).

\[
\mu_0 = \overbar{X} \pm t\cdot s/\sqrt{n}
\]

If the interval spans 0, then one is not significantly bigger than the other (or cannot be determined). 
As long as $n > 30$, it doesn't matter if the sample size is different between the random variables.

To find the 95\% Confidence Internval for the \textbf{true mean} $\mu$:
\[
\overbar{x} \pm t^*_{df=n-1} (s/\sqrt{n})
\]

$t^*$ has to be looked up based on the reference distrib.



\subsection{Types of Errors}
\begin{description}
\item[Type I]the null hypothesis is rejected when it is true
\item[Type II] the null hypothesis is accepted when it is false
\item[Power] the probability of correctly rejecting the null when the alternative is actually true.
\end{description}
$\alpha$ is \textit{level of significance} - probability of making a Type I error. The greater the cost of an error, the smaller $\alpha$ should be.
$\beta$ is the probability of making a Type II error. There is an inverse relation between Type I and II errors. Reducing one increases the other. The only way to reduce both is to increase $n$ the sample size.

\subsection{Pooled Two Sample $t$-Test}
\textbf{assumes equal variances}, different means, all observations are independent, random, $> 30$ or known normal distrib. 
\begin{align*}
H_0 :& \mu_1 - \mu_2 = 0 \\
T =& \frac{(\bar{x}_1 - \bar{x}_2) - (\mu_1 - \mu_2 | H_0) } {S_p \sqrt{\frac{1}{n_1} + \frac{1}{n_2}  } } \\
T  \sim& t_{df = n_1 + n_2 - 2} \\
CI: & (\bar{x}_1 = \bar{x}_2) \pm t^* \bigg(S_p \sqrt{\frac{1}{n_1} + \frac{1}{n_2}     }   \bigg) \\
S_p^2 &= \frac {(n_1 - 1)S_1^2) + (n_2 - 1)S^2_2  } { n_1 + n_2 -2 } \\
\end{align*}

Do not use if $\frac{S^2_1} {S^2_2} \geq 2$.

\subsection{Unpooled Two Sample $t$-Test}
\textbf{assumes unequal variances}, all observations independent, random, $> 30$ or known normal distrib. 
\begin{align*}
H_0 :& \mu_1 - \mu_2 = 0 \\
T =& \frac{(\bar{x}_1 - \bar{x}_2) - (\mu_1 - \mu_2 | H_0) } {\sqrt{\frac{S^2_1}{n_1} + \frac{S^2_2}{n_2}  } } \\
T  \sim& t_{df = min(n_1,n_2) - 1} \\
CI: & (\bar{x}_1 = \bar{x}_2) \pm t^* \bigg(S_p \sqrt{\frac{S^2_1}{n_1} + \frac{S^2_2}{n_2}    }    \bigg) \\
\end{align*}

Advantage Pooling: slightly more power to detect a difference. Disadvantage pooling: extra assumption could be wrong, with a high type I error rate.

\subsection{Paired Test}

This when there are two samples that are \textbf{not} independent, e.g. Weight Watchers, Before / After or matched, shared characteristics. 
Is the data matched or independent?
If we don't take into account the match, the results are wrong.
Applies when there are two obs for each study unit. 

To account for this, take the difference between $\overbar{X}_1 - \overbar{X}_2$ and then do a hypothesis test on the \textit{difference}. 

Basically it is a one-sample test on the differences. $H_0: \mu_D = 0$. $T \sim t_{df = n_D - 1}$

\subsubsection{Comparing Two Proportions}
(Not really covered in this class, but may be useful).
\[
Var(\hat{p}_1 - \hat{p}_2) = \frac{\hat{p}_1(1-\hat{p}_1)}{n_1} + \frac{\hat{p}_2(1-\hat{p}_2)}{n_2} 
\]

The 95\% confidence interval for $p_1-p_2$ is:
\[
(\hat{p}_1 - \hat{p}_2) \pm 1.96 \sqrt{\frac{\hat{p}_1(1-\hat{p}_1)}{n_1} + \frac{\hat{p}_2(1-\hat{p}_2)}{n_2}   }
\]

Decision Rules for Testing Two Proportions:
\[
T = \frac{(\hat{p}_1 - \hat{p}_2) }  { \sqrt{ \hat{p}(1-\hat{p}) (\frac{1}{n_1} + \frac{1}{n_2}) }} \text{, where } \hat{p} = \frac{n_1\hat{p}_1 + n_2\hat{p_2} } {n_1 + n_2 }
\]
$\hat{p}$ is called the \textit{pooled proportion}.


\subsubsection{Comparing Two Normal Distributions}

\begin{align*}
A \sim& \mathcal{N}(\mu_A, \sigma_A^2) \\
B \sim& \mathcal{N}(\mu_B, \sigma_B^2) \\
\end{align*}
Find $P(A < B + c)$ then Z-score:
\begin{align*}
P&(A - B - c < 0)\\
(A - B - c) \sim& \mathcal{N}(\mu_A - \mu_B - c, \sigma_A^2 + \sigma_B^2 - 2Cov(A,B)\\
P&(X = A - B - c > 0) \\
\end{align*}



\subsection{Assumptions}

\textbf{Robustness}: able to be useful when assumptions are violated. Check for violations graphically (QQplot, box plot, density) and look at the study design.
Under the null and correct assumptions, $p$-values should be uniformly distributed. $t$-test is very robust when sample sizes are large, or both groups
have the same size. Not so good when one group is very skewed. Fix with unpooled $t$ test, data transformations, or non-parametric tests.

\subsection{$F$-Distribution and $F$-tests}
\[
R = \frac{X/n_x} {Y/n_y} \sim F_{n_x, n_y} 
\]
Hypothesis: $H_0 : \sigma^2_x = \sigma^2_y, H_a: \sigma^2_x / \sigma^2_y \neq 1$.

Test statistic:
\[
F = \frac{ S^2_X} {S^2_Y } \sim F_{n_x - 1, n_y - 1}
\]

\subsection{Transformations}
Purpose: make data more symmetric

If Right skewed, use: $1/Y, log(Y), \sqrt{Y}$. Left skewed: $Y^2, e^Y, (n - Y)$

If done on log scale: 1) be cautious about $\leq 0$. Use ratios of medians as exp(mean) will not be useful. Consider rank transform.

\subsection{Rank Sum Test}

non-parametric, 2 indep. groups. Rank ALL data (2 groups combined) and sum up the ranks in one of the groups. Average ties. $H_0:$ medians are
the same. Reference distrib: small $n$ simulate like permutation test; large $n$ approx normality if $n_j \geq 10$: 
\[
T \sim N(n_x \bar{R}, S^2_R \frac {n_x n_y}{n_x + n_y})
\]

\subsubsection{Sign Test - Paired Data}
aka binomial test, nonparametric. Take all the differences

Hypotheses: $H_0 : P(D_i > 0) = P(Y_i > X_i) = 0.5.$

Test stat: $K= \sum_{i=1}^n I(D_i > 0).$ ie. count up the number of times the difference is $> 0 $.

Reference dist: Small $n: K \sim Binom(m, 0.5)$. Large $n: K \sim N(m/2, m/4)$. Large is considered $np > 10$ and $n(1-p) > 10$.

\subsubsection {Signed Rank Test}

Hypotheses: $H_0 : $ rank of magnitude of within pair differences is unrelated to the sign of the difference.

$D_i = Y_i - X_i$, and the calc Rank$(|D_i|)$ for all $n$ pairs.

Test stat: $W = \sum_{i=1}^n Ranks_{i|D_i > 0}$. 

Reference dist: small $n$: use permutation. Large $n: W \sim N(m(m+1)/4, m(m+1)(2m+1)/24)$

$m$ is the number of non-zero observations. Like the sign test, \textbf{we throw away the zeros}.

\subsection{Power}

Power increases with: larger $n$, moving alternate distrib further away, smaller $\sigma$ or $S$.

\[
n \geq \bigg(\frac{ (z^*) (\sigma) } {m}\bigg)^2
\]
\[
n \geq \bigg(\frac{\sigma(|z_{a/2}| + |z_{\beta}|)}{\mu_a - \mu_0}   \bigg)^2
\]

Bonferroni: $\alpha^* = \frac{\alpha}{tests}$. Prob of error: $1 - (1-\alpha)^I$

\subsection{ANOVA}
Comparing 3 or more groups. $F$-stat to test $H_0$
\[
F = \frac{MSB}{MSW} = \frac{SSB/df_B}{SSW/df_W} = \frac {SSB/(I-1)}  {SSW/(N-I)}
\]
Errors between groups: how far away is the variance of one group from all the other groups?
\[
SSM = SSB = \sum_{i=1}^I \sum_{j=1}^{n_i} (\bar{Y}_i - \bar{Y})^2 = \sum_{i=1}^I n_i (\bar{Y}_i - \bar{Y})^2
\]
with degrees of freedom $df_M = I - 1$.

Errors within groups: how far away is the variance within the group?
\[
SSE = SSW = \sum_{i=1}^I \sum_{j=1}^{n_i} (Y_{ij} - \bar{Y}_i)^2 = \sum_{i=1}^I (n_i - 1)S^2_i
\]
with degrees of freedom: $df_E = n - I$

There are two ways of determining which group differ. There are a number of techniques. 1) measure all
pair-wise combinations, 2) use contrasts.

Steps in a Complete ANOVA Procedure:
\begin{enumerate}
\item Examine the data, checking assumptions
\item If possible, formulate in advance some working (alternative)
hypotheses about how the population group means might differ. For example, if we are examining 
a control group vs two study groups, use
\[
H_0 : \mu_1 - \frac{1}{2}(\mu_2 + \mu_3) = 0
\]
This is called a \textbf{contrast}, which is a linear combination of $\mu$'s. The coefficents sum up to 0.
If the coefficients did not sum up to 0, then the null hypothesis would not hold. If the groups had different 
sample sizes, you could make the coefficient a weighting factor to adjust for this.

\item Check the evidence against the global null hypothesis of no
differences among the groups by calculating the F-test, or by testing all pairwise combinations. 
\item If the F-test is significant (that is, if it leads to a rejection of the
null hypothesis of equal population group means):
\begin{itemize}
\item Test the individual hypotheses specified at the second step
\item If there was not enough information to formulate working hypotheses, test all pairwise comparisons of means, adjusting for multiple comparisons (example also coming)
\end{itemize}
\end{enumerate}
\begin{tabular}{| c | c | c | c | c |}
\hline
Source & SS & DF & MS & F \\
\hline
Groups (between) & SSB & $I-1$ & $S^2_B = SSB/DFB$ & $F$ = MSB/MSW \\
Error (within) & SSW & $n-I$ & $S^2_w = SSW/DFW$ & \\
\hline
Total & SST & $n-1$ & SST/DFT & \\
\hline
\end{tabular}

\subsubsection{Contrast Test Hypothesis}
This is similar to a pooled test (we are assuming the variance among each group is the same):
\begin{align*}
H_0 :& \psi = 0 \\
H_a :& \psi \neq 0\\
T =& \cfrac{\sum a_i \overbar{Y}_i } {S_p \sqrt{\sum \frac{a_i^2}{n_i} } }\\
\end{align*}
This $t$-test has a $t$ distribution with degrees of freedom associated with $S_p$ under $H_0$. The 
test can be 1- or 2-sided.

For this $t$-test, what is the variance? If the separate groups were not independent, it would be
$Var(X+Y+Z) = Var(X) + Var(Y) + Var(Z) + 2\cdot Cov(X,Y) + 2\cdot Cov(X,Z) + 2\cdot Cov(Y,Z)$. 
However, we are assuming that the variance of each of the groups is independent, so 
$Var(X+ Y + Z) = Var(X) + Var(Y) + Var(Z)$.

Recall $\psi = \mu_1 + \frac{1}{2}(\mu_2 + \mu_3)$. The variance would be 
\begin{align*}
Var =& Var(\overbar{Y}_1) + Var(-\frac{1}{2} \overbar{Y}_2) + Var(-\frac{1}{2}\overbar{Y}_3)\\
	=& \sigma^2\bigg(\frac{1}{n_1} + \frac{(-1/2)^2}{n_2} + \frac{(-1/2)^2}{n_3}  \bigg) \\
E(S_p^2) =& \sigma^2 \\
sd =& S_p \sqrt{(\frac{1}{n_1} + \frac{(-1/2)^2}{n_2} + \frac{(-1/2)^2}{n_3}  }\\
T =& \cfrac{\bar{Y}_1 - \frac{1}{2}(\bar{Y}_2 + \bar{Y}_3) } { S_p \sqrt{(\frac{1}{n_1} + \frac{(-1/2)^2}{n_2} + \frac{(-1/2)^2}{n_3}  }} \\
S^2_p =& SSE / df_E  \text{ (denom of $F$ test)}\\
\end{align*}


\subsubsection{Multiple Comparisons}

Since contrast tests involves multiple comparisons, we have an inflated risk of type I errors. This can
be corrected using the Bonferroni correction, where $\alpha^* = \alpha / $(number of tests).

For $N$ simultaneous tests that are independent, the overall type I error (ie. the probability of at least
one type I error among N tests) is $1 - (1 - \alpha)^N$.

For $N$ simultaneous tests that are perfectly positively dependent (if one rejects, then the other
combinations are likely to reject as well, even if the groups are independent), the overall type I error is just $\alpha$.

For $N$ simultaneous tests that have unknown dependence, the maximum overall type I error is $min(N\alpha, 1)$ (since it is a probability, it can't be $> 1$), where

\[
\alpha \leq 1- (1-\alpha)^N \leq N \alpha
\]


\subsubsection{Tukey Honest Significant Difference (HSD)}

This is the correct adjustment under ANOVA. Basic idea: consider the \textit{largest difference} between any
two sample means for for $I$ groups. 

Intuition: There are $\bar{Y}_1, \bar{Y}_2, \ldots, \bar{Y}_I$ sample means. To do a pairwise comparison
would generate ${I \choose 2}$ 2 sample $t$-tests. We are going to reject one of these with 5\% comparison
rates. So it reduces to only have to check the ratio of max and min sample means.

It is appropriate when interested in differences between all pairs of group
means. We assume normality, equal variances, equal sample sizes($\bar{n}$), and equal means.

\[
Q = \frac{\bar{Y}_{max} - \bar{Y}_{min}}  {S_p \sqrt{ \bar{n}}} \sim q(1 - \alpha, n-I) \text{, where } n = \bar{n}I
\]

The Tukey distribution $q$ is called the \textbf{Studentized Range Distribution}. In R, use \texttt{qtukey()} to obtain quantiles.

The margin of for the Confidence Interval (This is also used for the critical value as part of the $t$-test):
\[
\bigg(\frac{q(1-\alpha,I,n-I) } {\sqrt{2} }    \bigg) SE \text{, where }SE = S_p \sqrt{\frac{1}{\bar{n}} + \frac{1}{\bar{n}} }
\]




\subsubsection{Two-way and multi-way ANOVA}

One way ANOVA - onlyone factor affecting the groups.

Two way ANOVA - multiple grouping variables to compare groups.

This can be reduced to boxplot

\textbf{Interactive effect}: when one variable changes the other variable. E.g. by going from
sophomore to junior, the number of texts would change.  degrees of freedom = $(I_1 -1)*(I_2  -1 ) = (4-1)*(2-1) = 3$

\subsection{Kruskal-Wallis Test}
This is a form of ANOVA on Ranks rather than $t$-test. The KW test is just an extension of the Wilcoxon Rank Sum test to 3 or more groups. The same procedure as other rank tests:

\begin{enumerate}
\item Rank all the combined data ignoring groups from 1 to $N$ (treating them all like one sample).
For any ties, average those ranks.
\item Calculate an $F$ like $\chi^2$ test statistic:
\[
K = (N -1) \frac {\sum_{i=1}^I n_i (\bar{R}_i - \bar{R})^2 }  
			{ \sum_{i=1}^I\sum_{j=1}^{n_i} (R_{ij} - \bar{R})^2    } \sim \chi^2_{i-1}
\]
The hypothesis is like the Rank-Sum test: the quantiles in the group are all the same.
\end{enumerate} It is $\chi^2$ because the numerator and denomiator are tightly related. Only the numerator is a random 
variable.


% You can even have references
%\rule{0.3\linewidth}{0.25pt}
\scriptsize
\bibliographystyle{abstract}
\bibliography{refFile}
\end{multicols*}
\end{document}