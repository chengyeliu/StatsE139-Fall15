\documentclass[10pt,landscape]{article}
\usepackage{multicol}
\usepackage{calc}
\usepackage{ifthen}
\usepackage[landscape]{geometry}
\usepackage{amsmath,amsthm,amsfonts,amssymb}
\usepackage{color,graphicx,overpic}
\usepackage{hyperref}


\pdfinfo{
  /Title (example.pdf)
  /Creator (TeX)
  /Producer (pdfTeX 1.40.0)
  /Author (David Wihl)
  /Subject (Cheat Sheet)
  /Keywords (pdflatex, latex,pdftex,tex)}

% This sets page margins to .5 inch if using letter paper, and to 1cm
% if using A4 paper. (This probably isn't strictly necessary.)
% If using another size paper, use default 1cm margins.
\ifthenelse{\lengthtest { \paperwidth = 11in}}
    { \geometry{top=.5in,left=.5in,right=.5in,bottom=.5in} }
    {\ifthenelse{ \lengthtest{ \paperwidth = 297mm}}
        {\geometry{top=1cm,left=1cm,right=1cm,bottom=1cm} }
        {\geometry{top=1cm,left=1cm,right=1cm,bottom=1cm} }
    }

% Turn off header and footer
\pagestyle{empty}

% Redefine section commands to use less space
\makeatletter
\renewcommand{\section}{\@startsection{section}{1}{0mm}%
                                {-1ex plus -.5ex minus -.2ex}%
                                {0.5ex plus .2ex}%x
                                {\normalfont\large\bfseries}}
\renewcommand{\subsection}{\@startsection{subsection}{2}{0mm}%
                                {-1explus -.5ex minus -.2ex}%
                                {0.5ex plus .2ex}%
                                {\normalfont\normalsize\bfseries}}
\renewcommand{\subsubsection}{\@startsection{subsubsection}{3}{0mm}%
                                {-1ex plus -.5ex minus -.2ex}%
                                {1ex plus .2ex}%
                                {\normalfont\small\bfseries}}
\makeatother

\newcommand{\overbar}[1]{\mkern 1.5mu\overline{\mkern-1.5mu#1\mkern-1.5mu}\mkern 1.5mu}


% Define BibTeX command
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

% Don't print section numbers
\setcounter{secnumdepth}{0}


\setlength{\parindent}{0pt}
\setlength{\parskip}{0pt plus 0.5ex}

%My Environments
\newtheorem{example}[section]{Example}
% -----------------------------------------------------------------------

\begin{document}
\raggedright
\footnotesize
\begin{multicols*}{3}


% multicol parameters
% These lengths are set only within the two main columns
%\setlength{\columnseprule}{0.25pt}
\setlength{\premulticols}{1pt}
\setlength{\postmulticols}{1pt}
\setlength{\multicolsep}{1pt}
\setlength{\columnsep}{2pt}
\setlength{\columnseprule}{1pt}


\subsubsection{Basics}

\begin{tabular}{| c | c | c| }
\hline
 & Sample statistic &  Population Parameter \\
 \hline
 Mean & $\overbar{X}$ & $\mu$ \\
 Variance & $S^2$ & $\sigma^2$ \\
 Correlation & $r$ & $\rho$ \\
  Noise & $e_i$ & $\epsilon_i$ \\
\hline
& Guess & True, but unknown \\
\hline
\end{tabular}

The Mean, Variance and StdDev are subject to outliers.
\begin{align*}
\overbar{X} =& \frac{1}{n} \sum\limits_{i=1}^n x_i \\
\mu = E(W) =& E(a + bX) = a + bE(X)\\
\sigma^2 = Var(X) =& E[X^2] - \mu_x^2\\
S^2 =& \sum\limits_{all\ i} \frac{(X_i - \overbar{X})^2}{n-1}\\
\sigma = StdDev(X) =& \sqrt{\sigma^2}\\
Var(X) =& E[(X - \mu)^2]  = E(X^2) - \mu^2\\
	=& \sum_{all x} (x - \mu_x)^2 P(X = x)\\
	=& E(X^2) - E(X)^2 = E(X - E(X))^2\\
Var(X + c) =& Var(X)\\
Var(cX) =& c^2Var(X)\\
Var(\bar{X}) =& \frac{\sigma^2}{n} \\
 \text{If X,Y are dependent}\\
Var(X+Y) \ne& Var(X) + Var(Y)\\
Var(X + Y) =& Var(X - Y)\\
Var((a + bX) + (c + dY)) =& b^2Var(X) + d^2Var(Y) + 2bdCov(X,Y)\\
Var(aX + bY) =& a^2 Var(X) + b^2(Y) + 2abCov(X,Y) \\
	=& a^2 Var(X) + b^2(Y) + 2ab\sigma_x \sigma_y \rho_{xy}\\
\end{align*}
Quartiles split the data into 4 equal groups by number of values, or 25\% percentiles.
Q2 is the median.

\subsubsection{Study Design}

Types of variables: categorical vs. quantitative, dummy, discrete vs continuous.
Observational vs Experiments. Only experimentals can show causal effects.
Key factors to an experiment: control group, randomized, and replicated. Usually 30 replications is sufficient.
Avoid confounding by having cross-over groups.

\textbf{Scope of Inference}: \textbf{Interval Validity}: low when 1) unaccounted confounding factors, 2) ignored missing data 3) noncompliance 4) unverified assumptions
5) suboptimal method of analysis. Applicable when allocation of units to groups is random.
 \textbf{External Validity}: high when can be generalized to population. Applicable when selection of units is random.


\subsubsection{Covariance and Correlation}
Covariance gives direction.\\
Correlation gives direction and strength.\\
Both are \textit{linear}.
\begin{align*}
Cov(X, Y) =& \frac{1}{N} \sum\limits_{i=1}^{N} {(x_i - \overbar{x})(y_i - \overbar{y})} \\
Cor =& \frac{Cov}{\sigma_x \cdot \sigma_y}\\
\end{align*}



\subsubsection{Probabilities}
$ 0 \leq $ All probabilities $ \leq 1 $\\
\textit{Mutually exclusive and Exhaustive}\\
\begin{align*}
P(\overbar{A}) =& 1 - P(A)\\
P(A \text{ or } B) =& P(A) + P(B) - P(A \text{ and } B)\\
P(A \vert B) =& \frac{P(A \text{ and } B)}{P(B)}\\
P(B) =& \sum_{i=1}^n P(B \cap A_i) = \sum_{i=1}^n P(B | A_i)((A_i)\\
{n \choose k} =& \frac{n!}{k!(n-k)!} \\
\end{align*}
Joint vs. Marginal probabilities\\
Independent if $P(A\vert B) = P(A)$\\
For Independent only: $P(E \text{ and } F) = P(E)\cdot P(F)$\\
\begin{tabular}{| c | c | c |}

\hline
&B &$\overbar{B}$\\
\hline
A & $P(A and B) = P(B)P(A \vert B)$ & $P(A and \overbar{B}) = P(\overbar{B})P(A \vert \overbar{B})$\\
$\overbar{A}$ & $P(\overbar{A} and B) = P(\overbar{A})P(B\vert \overbar{A})$ & $ P(\overbar{A}  and \overbar{B}) = P(\overbar{A})P(\overbar{B} \vert \overbar{A})$ \\
\hline
\end{tabular}

\begin{tabular}{| c | c |}
\hline
all success & $p^n$\\
all failure & $(1-p)^n$\\
at least one failure & $1-p^n$\\
at least one success & $1 - (1-p)^n$\\
\hline
\end{tabular}


\subsubsection{Random Variables}
\begin{align*}
P(X \le x) \rightarrow& CDF\\
E(cX) =& c\cdot E(X)\\
E(X+c) =& E(X) + c\\
E(X+Y) =& E(X) + E(Y)\\
\end{align*}

If $X_1, \ldots , X_n \sim N(\mu, \sigma^2)$ then $\bar{X} \sim N(\mu_{\bar{X}} = \mu, \sigma^2_{\bar{X}} = \sigma^2/n)$. If pop dist is not normal, $S^2$ will eventually be Normal
but may not be independent.


\subsubsection{Bias of an Estimator}
In practice $n$ has to relatively much larger like $> 100$.



Guesses should be \textit{unbiased} and have \textit{minimum variance}. MVUE (Minimum Variance, Unbiased Estimates).
\[
bias(\hat{\theta}) = E(\hat{\theta}) - \theta
\]
Unbiased if $bias = 0$ (expected value equals true, not a particular value of $\overbar{x}$). 

For samples, we divide by $n-1$ instead of $n$ to make an unbiased estimator. The guess would otherwise be too low.
\[
E(X) = \sum_{all x} xP(X=x) 
\]
\[
E(\overbar{X}) = \sum\limits_{i=1}^{\infty} x_i p_i =  \mu
\]
\[
E(S^2) = \sigma^2
\]
\begin{align*}
E[X + c] =& E[X] + c\\
E[X + Y] =& E[X] + E[Y]\\
E[aX] =& a E[X]\\
E[aX + bY + c] =& aE[X] + bE[Y] +c\\
E((a + bX) + (c_dY)) =& a + bE(X) + c + dE(Y)\\
\end{align*}
Example: Roulette has a \$1 bet with a \$35 payoff for $\frac{1}{38}$ odds.
\[
E[\text{gain from a \$1 bet}] = -\$1 \cdot \frac{37}{38} + \$35 \cdot \frac{1}{38} = -\$0.0526
\]


\subsubsection{Uniform Distribution}
\begin{align*}
E(X) =& \frac{(a+b)}{2}\\
Var(X) =& \frac{(b-a)^2}{12} \\
\end{align*}
\ \ $y$ axis should be a fraction to make area $=1$

\subsubsection{Normal Distribution}
\begin{align*}
X \sim& \mathcal{N}(\mu,\sigma^2)\\
Z = &\frac{X - \mu}{\sigma} \sim \mathcal{N}(0,1)\\
X = &\sigma Z + \mu \\
\Phi(z) =& \text{distribution} \\
P(a \leq X \leq b) =& P[(a-\mu) \leq (X-\mu) \leq (b-\mu)]\\
	= & P[\frac{(a-\mu)}{\sigma} \leq \frac{(X-\mu)} {\sigma} \leq \frac {(b-\mu)} {\sigma} ]\\
	= & P[\frac{(a-\mu)}{\sigma} \leq Z \leq \frac {(b-\mu)} {\sigma} ]\\
\end{align*}
Linear combination of normals is normal. Used by CLT.


\subsubsection{Binomial Distribution}

\begin{itemize}
\item{$n$ independent trials}
\item{binary result}
\item{same probability of success}
\item{total number of successes}
\end{itemize}
\begin{align*}
X \sim& Bin(n,p)\\
\binom{n}{x} =& \frac{n!}{x!(n-x)!}\\
P(X=x) =& \frac{n!}{x!(n-x)!}p^xq^{(n-x)}\\
\mu_x = E(X) =& n \cdot p\\
\sigma^2 = Var(X) =& n \cdot p \cdot q = n \cdot p \cdot (1-p)\\
X \sim& N(\mu =np, \sigma = \sqrt{np(1-p)}) \\
\hat{p} \sim& N(\mu = p, \sigma\sqrt{p(1-p)/n} ) \\
\end{align*}
Shape of distribution depends on $p,n$.\\
Small $p$, left skewed. Large $p$, right skewed




\subsection{Hypothesis Test - General}
A \textbf{scientific hypothesis} makes a testable statement about the observable universe.

A \textbf{statistical hypothesis} is more restricted. It concerns the behavior of a measurable (or observable) 
random variable. It is often a statement or claim about a parameter of a population or distribution.

\begin{enumerate}
\item Formulate hypotheses ($H_0, H_a, \alpha$)
\item Calculate test statistic and reference distrib.
\item Calculate $p$-value based on reference distribution of test statistic $|H_0$. \textbf{$p$ value is NOT the probability that the null hypothesis is true.} 
It is probablity of seeing our data on the null hypothesis. 
\item Determine conclusion and scope of inference
\end{enumerate}
\textbf{Note:} $t$ values are measures of \textit{distance}. $p$ values are measure of \textit{probability}. Assumptions? Independence? Distribution of Observations? Parametric vs. non-parametric?

\begin{tabular}{ c  c }
Hypotheses & Decision Rule \\
\hline
$H_0 : \mu = \mu_0$ \\      $H_a : \mu \neq \mu_0$ & If $|t_{stat}| > 1.96$, reject $H_0$ \\
 & \\
$H_0 : \mu = \mu_0$ \\ $H_a : \mu < \mu_0$      & If $t_{stat} < -1.64$, reject $H_0$ \\
 & \\
$H_0 : \mu = \mu_0$ \\ $H_a : \mu > \mu_0$      & If $t_{stat} > 1.64$, reject $H_0$ \\
\end{tabular}


Assumptions:
\begin{enumerate}
\item Observations are \textbf{independent}. This is true if the sample is randomly selected, but false if there is bias in the sampling.
\item \textbf{Normal Distributions} of the observations. This happens when the sample is large enough (via the Central Limit Theorm) or it is known that the population is normally distributed.
\end{enumerate}

If these assumptions are not correct, none of the $t$-tests will work correctly.


\subsubsection{Hypothesis Test - Mean}

Calculation by hand using a $t$ test:
\begin{align*}
t_{stat} =& \frac{ \overbar{x} - \mu_0  } { s / \sqrt{n}  } \\
\end{align*}



\subsection{Fisher's Randomization Test}

For casual inference in experiments. No assumption as to the underlying distribution has to be made. Generally, is $\mu_1 = \mu_2$? 

The only assumption is Additive Treatment Effect ($\delta$):
\[
Y_{c,i} = Y_{v,i} + \delta
\]

$H_0: \delta = 0$, ie  zero treatment effect for all units. $H_a: \delta \neq 0$ non-zero treatment effect for ALL units. Reference distrib built through simulation. Non-parametric.

Assumptions:
\begin{itemize}
\item Random assignment to groups
\item Under $H_0$, \textit{independence, interchangability} of study units. 
\end{itemize}

Test Statistic: Difference of outcomes of the two groups: (could also use difference between the medians)
\[
\hat{\delta} = \overbar{Y}_c - \overbar{Y}_v
\]

The maximum number of possible simulations is the binomial distribution:
\[{t \choose s}\]
where $t$ is the total number of study units and $s$ is the number where the effect was shown.

Calculating $p$ value: The $p$ value is proportion of values above or below the observed test statistic.
\begin{align*}
\hat{\delta} =& 0.5\\
p =& P(\overbar{Y}_c - \overbar{Y}_v \geq \overbar{y}_c - \overbar{y}_v) \\
   =& P(\overbar{Y}_c - \overbar{Y}_v \geq 0.5) = 0.029
\end{align*}

so there is sufficient evidence to reject the null.

Scope of inference: Internal Validity maybe not if the same hospital. External validity: possibly not, as these were volunteers.

\subsubsection{Permutation Test}
For observational studies, comparing two groups - for generalization. Means of observations are presumed the same $E(Y_{1,i}) = \mu_1, E(Y_{2,j}) = \mu_2. H_0  : \mu_1 = \mu_2$.

Test stat: $\hat{D} = \bar{Y}_i - \bar{Y}_1$. Reference distrib by simulation. 
Assumes independence of study units and groups, nonparametric, similar shapes and spreads.

\subsubsection{All Things $\chi^2$}

\begin{align*}
\chi^2_1 =& Z^2 \\
\chi^2_n =& \sum\limits_{i=1}^n Z^2_i \\
t_n =& \frac{Z} {\sqrt{\chi^2_n / n} } \\
F_{n,m} =& \frac{ \chi^2_n / n} { \chi^2_m / m } \\
\chi^2_{n+m} =& \chi^2_n + \chi^2_m \\
\frac{(n-1) S^2} {\sigma^2} \sim& X^2_{df = n-1} \\
S^2 = \frac{1}{n-1}\sum\limits_{i=1}^n (X_i - \overbar{x})^2 \sim& \frac{\sigma^2}{n-1}\chi^2_{df=n-1} \\
\end{align*}

\subsection{The $t$ distribution}
The $t$ distribution has a slightly wider spread in the tails than Standard Normal. Also known as student-t distribution. This happens when you don't know the
real $\sigma$ and are forced to use $S$, which is less reliable.

\[
\overbar{X} \approx N(\mu, \frac{\sigma^2}{n})
\]

allows us to Z-score
\[
Z = \frac{\overbar{X} - \mu}{\sigma / \sqrt{n}}
\]
but we don't know $\sigma$ so in practice we use
\[
T = \frac{\overbar{X} - \mu}{S / \sqrt{n}} \sim t_{n-1}
\]
(which has two random variables ($\overbar{X}$ and $S$). Now, take that previous definition of $T$ and add $\sigma/\sqrt{n}$ to the top and bottom:

\begin{align*}
T =& \frac{\overbar{X} - \mu}{S / \sqrt{n}} \\
   =&  \frac{(\overbar{X} - \mu) / (\sigma/\sqrt{n})}{(S / \sqrt{n}) / (\sigma/\sqrt{n})}\\
   =& \frac{Z}{\sqrt{S^2/\sigma^2}}\\
   =& \frac{Z}{\sqrt{\frac{(n-1)S^2}{(n-1)\sigma^2}}} \\
 =&  \frac{Z}{\sqrt{\chi^2/df}}\text{, since }\chi^2 = \frac{(n-1)S^2}{\sigma^2}
\end{align*}

Assumptions: 1) Observations are independent (randomly selected), 2) Normal distrib of observations (either $>30$ via CLT or pop. is known $ \sim N(\mu,\sigma^2)$).



\subsubsection{Confidence Intervals}

CI is Estimate $\pm$ margin of error or Estimate $\pm$ ($z$ value) $\times$ (SD of estimate).

\[
\mu_0 = \overbar{X} \pm t\cdot s/\sqrt{n}
\]

If the interval spans 0, then one is not significantly bigger than the other (or cannot be determined). 
As long as $n > 30$, it doesn't matter if the sample size is different between the random variables.

To find the 95\% Confidence Internval for the \textbf{true mean} $\mu$:
\[
\overbar{x} \pm t^*_{df=n-1} (s/\sqrt{n})
\]

$t^*$ has to be looked up based on the reference distrib.



\subsection{Types of Errors}
\begin{description}
\item[Type I]the null hypothesis is rejected when it is true
\item[Type II] the null hypothesis is accepted when it is false
\item[Power] the probability of correctly rejecting the null when the alternative is actually true.
\end{description}
$\alpha$ is \textit{level of significance} - probability of making a Type I error. The greater the cost of an error, the smaller $\alpha$ should be.
$\beta$ is the probability of making a Type II error. There is an inverse relation between Type I and II errors. Reducing one increases the other. The only way to reduce both is to increase $n$ the sample size.

\subsection{Pooled Two Sample $t$-Test}
\textbf{assumes equal variances}, different means, all observations are independent, random, $> 30$ or known normal distrib. 
\begin{align*}
H_0 :& \mu_1 - \mu_2 = 0 \\
T =& \frac{(\bar{x}_1 - \bar{x}_2) - (\mu_1 - \mu_2 | H_0) } {S_p \sqrt{\frac{1}{n_1} + \frac{1}{n_2}  } } \\
T  \sim& t_{df = n_1 + n_2 - 2} \\
CI: & (\bar{x}_1 = \bar{x}_2) \pm t^* \bigg(S_p \sqrt{\frac{1}{n_1} + \frac{1}{n_2}     }   \bigg) \\
S_p^2 &= \frac {(n_1 - 1)S_1^2) + (n_2 - 1)S^2_2  } { n_1 + n_2 -2 } \\
\end{align*}

Do not use if $\frac{S^2_1} {S^2_2} \geq 2$.

\subsection{Unpooled Two Sample $t$-Test}
\textbf{assumes unequal variances}, all observations independent, random, $> 30$ or known normal distrib. 
\begin{align*}
H_0 :& \mu_1 - \mu_2 = 0 \\
T =& \frac{(\bar{x}_1 - \bar{x}_2) - (\mu_1 - \mu_2 | H_0) } {\sqrt{\frac{S^2_1}{n_1} + \frac{S^2_2}{n_2}  } } \\
T  \sim& t_{df = min(n_1,n_2) - 1} \\
CI: & (\bar{x}_1 = \bar{x}_2) \pm t^* \bigg(S_p \sqrt{\frac{S^2_1}{n_1} + \frac{S^2_2}{n_2}    }    \bigg) \\
\end{align*}

Advantage Pooling: slightly more power to detect a difference. Disadvantage pooling: extra assumption could be wrong, with a high type I error rate.

\subsection{Paired Test}

This when there are two samples that are \textbf{not} independent, e.g. Weight Watchers, Before / After or matched, shared characteristics. 
Is the data matched or independent?
If we don't take into account the match, the results are wrong.
Applies when there are two obs for each study unit. 

To account for this, take the difference between $\overbar{X}_1 - \overbar{X}_2$ and then do a hypothesis test on the \textit{difference}. 

Basically it is a one-sample test on the differences. $H_0: \mu_D = 0$. $T \sim t_{df = n_D - 1}$

\subsubsection{Comparing Two Proportions}
(Not really covered in this class, but may be useful).
\[
Var(\hat{p}_1 - \hat{p}_2) = \frac{\hat{p}_1(1-\hat{p}_1)}{n_1} + \frac{\hat{p}_2(1-\hat{p}_2)}{n_2} 
\]

The 95\% confidence interval for $p_1-p_2$ is:
\[
(\hat{p}_1 - \hat{p}_2) \pm 1.96 \sqrt{\frac{\hat{p}_1(1-\hat{p}_1)}{n_1} + \frac{\hat{p}_2(1-\hat{p}_2)}{n_2}   }
\]

Decision Rules for Testing Two Proportions:
\[
T = \frac{(\hat{p}_1 - \hat{p}_2) }  { \sqrt{ \hat{p}(1-\hat{p}) (\frac{1}{n_1} + \frac{1}{n_2}) }} \text{, where } \hat{p} = \frac{n_1\hat{p}_1 + n_2\hat{p_2} } {n_1 + n_2 }
\]
$\hat{p}$ is called the \textit{pooled proportion}.


\subsubsection{Comparing Two Normal Distributions}

\begin{align*}
A \sim& \mathcal{N}(\mu_A, \sigma_A^2) \\
B \sim& \mathcal{N}(\mu_B, \sigma_B^2) \\
\end{align*}
Find $P(A < B + c)$:
\begin{align*}
P&(A - B - c < 0)\\
(A - B - c) \sim& \mathcal{N}(\mu_A - \mu_B - c, \sigma_A^2 + \sigma_B^2 - 2Cov(A,B)\\
P&(X = A - B - c > 0) \\
\end{align*}
then Z-score


\subsection{Assumptions}

\textbf{Robustness}: able to be useful when assumptions are violated. Check for violations graphically (QQplot, box plot, density) and look at the study design.
Under the null and correct assumptions, $p$-values should be uniformly distributed. $t$-test is very robust when sample sizes are large, or both groups
have the same size. Not so good when one group is very skewed. Fix with unpooled $t$ test, data transformations, or non-parametric tests.

\subsection{$F$-Distribution and $F$-tests}
\[
R = \frac{X/n_x} {Y/n_y} \sim F_{n_x, n_y} 
\]
Hypothesis: $H_0 : \sigma^2_x = \sigma^2_y, H_a: \sigma^2_x / \sigma^2_y \neq 1$.

Test statistic:
\[
F = \frac{ S^2_X} {S^2_Y } \sim F_{n_x - 1, n_y - 1}
\]

\subsection{Transformations}
Purpose: make data more symmetric

If Right skewed, use: $1/Y, log(Y), \sqrt{Y}$. Left skewed: $Y^2, e^Y, (n - Y)$

If done on log scale: 1) be cautious about $\leq 0$. Use ratios of medians as exp(mean) will not be useful. Consider rank transform.

\subsection{Rank Sum Test}

non-parametric, 2 indep. groups. Rank ALL data (2 groups combined) and sum up the ranks in one of the groups. Average ties. $H_0:$ medians are
the same. Reference distrib: small $n$ simulate like permutation test; large $n$ approx normality if $n_j \geq 10$: 
\[
T \sim N(n_x \bar{R}, S^2_R \frac {n_x n_y}{n_x + n_y})
\]

\subsubsection{Sign Test - Paired Data}
aka binomial test, nonparametric. Take all the differences

Hypotheses: $H_0 : P(D_i > 0) = P(Y_i > X_i) = 0.5.$

Test stat: $K= \sum_{i=1}^n I(D_i > 0).$ ie. count up the number of times the difference is $> 0 $.

Reference dist: Small $n: K \sim Binom(m, 0.5)$. Large $n: K \sim N(m/2, m/4)$. Large is considered $np > 10$ and $n(1-p) > 10$.

\subsubsection {Signed Rank Test}





% You can even have references
%\rule{0.3\linewidth}{0.25pt}
\scriptsize
\bibliographystyle{abstract}
\bibliography{refFile}
\end{multicols*}
\end{document}